# ==========================================
# Copy these commands into RunPod SSH terminal
# Execute them ONE BY ONE
# ==========================================

# 1. Create server/config_server.yaml
cat > ~/1UP_2/server/config_server.yaml << 'EOF'
# 1UP Server Configuration - RunPod GPU
# Optimized for CUDA processing with maximum detection

sam3:
  device: "cpu"  # CPU for local testing, change to "cuda" for RunPod GPU
  filtering:
    enabled: false  # Detect EVERYTHING, let Claude filter
  enhance_image: true  # CLAHE for dark objects
  text_prompt: ""  # Empty = automatic (uses "visual" prompt)

claude:
  api_key_env: "CLAUDE_API_KEY"  # Read from environment
  model: "claude-sonnet-4-20250514"
  max_tokens: 16000  # For large batches

storage:
  crops_dir: "images/crops"
  raw_dir: "images/raw"

# Server settings
server:
  host: "0.0.0.0"
  port: 8000
  workers: 1  # Single worker for GPU (don't parallelize GPU work)
EOF

# 2. Create client/config_client.yaml
cat > ~/1UP_2/client/config_client.yaml << 'EOF'
# 1UP Client Configuration - Local Capture
# Captures frames and sends to server for processing

camera:
  # Reolink RTSP stream (4K for maximum quality)
  source: "rtsp://admin:Polic!ia1@192.168.1.188:8554/h264Preview_01_main"
  resolution: [3840, 2160]  # 4K for maximum crop quality
  fps: 2
  buffer_size: 1  # Low latency for RTSP
  
  # Image quality validation
  quality_check:
    enabled: true
    min_sharpness: 20.0  # Reject blurry frames
    warning_sharpness: 50.0

server:
  # RunPod server URL (update with your RunPod endpoint)
  url: "http://localhost:8000"  # Default local, update to RunPod IP:port
  timeout: 120  # 2 minutes timeout for processing
EOF

# 3. Create requirements.txt
cat > ~/1UP_2/requirements.txt << 'EOF'
# 1UP - Dependencies

# Core ML/AI
torch>=2.0.0
torchvision>=0.15.0

# Computer Vision
opencv-python>=4.8.0
Pillow>=10.0.0

# SAM 3 (Segment Anything Model 3)
# Install via:
#   git clone https://github.com/facebookresearch/sam3.git
#   cd sam3 && pip install -e .
#   # Request access to checkpoints at SAM 3 HuggingFace repo
#   # Authenticate: hf auth login
# Additional dependencies for SAM 3:
einops>=0.8.0
pycocotools>=2.0.0
psutil>=7.0.0
omegaconf>=2.3.0

# Claude API
anthropic>=0.18.0

# Configuration
PyYAML>=6.0

# Web Application
Flask>=3.0.0
EOF

# 4. Create server/requirements_server.txt
cat > ~/1UP_2/server/requirements_server.txt << 'EOF'
# 1UP Server Dependencies - RunPod GPU
# Install with: pip install -r server/requirements_server.txt

# Core ML/AI
torch>=2.0.0
torchvision>=0.15.0

# Computer Vision
opencv-python>=4.8.0
Pillow>=10.0.0

# SAM 3 (Segment Anything Model 3)
einops>=0.8.0
pycocotools>=2.0.0
psutil>=7.0.0
omegaconf>=2.3.0

# Claude API
anthropic>=0.18.0

# Configuration
PyYAML>=6.0

# FastAPI
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.0.0

# HTTP client (for health checks)
httpx>=0.25.0
EOF

echo "âœ… Config files created!"
echo "Next: We'll create Python files using a different method..."
